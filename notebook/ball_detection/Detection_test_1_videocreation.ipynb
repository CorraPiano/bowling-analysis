{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to create the new video with detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the relative path to the video file\n",
    "notebook_dir = Path().resolve()\n",
    "project_root = notebook_dir.parent.parent\n",
    "video_path = project_root / \"data\" / \"recording_2\" / \"Recording_2_normal_speed.mp4\"\n",
    "video_path = str(video_path)  # Convert Path object to string for OpenCV\n",
    "\n",
    "# Load the video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check if video opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get video properties\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Define the output video file path\n",
    "output_video_path = project_root / \"data\" / \"recording_2\" / \"output_detected_test_1.mp4\"\n",
    "output_video_path = str(output_video_path)\n",
    "\n",
    "# Initialize video writer\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 276 frames.\n"
     ]
    }
   ],
   "source": [
    "# Background Subtraction\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=16, detectShadows=True)\n",
    "bg_subtractor.setVarThresholdGen(25)\n",
    "\n",
    "for _ in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))-40):\n",
    "    ret, frame_bg = cap.read()\n",
    "    if not ret: \n",
    "        print(\"Warning: Could not read frame during warm-up.\")\n",
    "        break\n",
    "    bg_subtractor.apply(frame_bg)\n",
    "\n",
    "# Initial settings\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "frame_count = 0\n",
    "\n",
    "# Creating the new frames\n",
    "while frame_count < cap.get(cv2.CAP_PROP_FRAME_COUNT):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: \n",
    "        print(\"Error: Could not read frame from video.\")\n",
    "        break\n",
    "\n",
    "    # Apply background subtraction\n",
    "    fg_mask = bg_subtractor.apply(frame)\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_OPEN, kernel)\n",
    "    fg_mask = cv2.medianBlur(fg_mask, 5)\n",
    "    blurred = cv2.GaussianBlur(fg_mask, (9, 9), 2)\n",
    "\n",
    "    # Hough Circle Detection\n",
    "    circles = cv2.HoughCircles(\n",
    "        blurred, cv2.HOUGH_GRADIENT, dp=1.2, minDist=100,\n",
    "        param1=50, param2=30, minRadius=30, maxRadius=100\n",
    "    )\n",
    "\n",
    "    # Draw and process only the first detected circle\n",
    "    output = frame.copy()\n",
    "    if circles is not None:\n",
    "        circles = np.uint16(np.around(circles))\n",
    "        \n",
    "        # Process only the first circle\n",
    "        first_circle = circles[0, 0]\n",
    "        x, y, r = first_circle\n",
    "        cv2.circle(output, (x, y), r, (0, 255, 0), 3)\n",
    "        cv2.circle(output, (x, y), 2, (0, 0, 255), 3)\n",
    "    \n",
    "    # Write the frame with detected circles to the output video\n",
    "    out.write(output)\n",
    "    frame_count += 1\n",
    "\n",
    "# Check\n",
    "print(f\"Processed {frame_count} frames.\")\n",
    "cap.release() \n",
    "out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I want to take only the region of the ball:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Before the while loop\\nball_images = []  # List to store extracted ball images\\n\\n# In the while loop (after the drawing circles)\\nball = frame[y-r:y+r, x-r:x+r]\\nif ball.size > 0:\\n    ball_rgb = cv2.cvtColor(ball, cv2.COLOR_BGR2RGB)\\n    ball_images.append(ball_rgb)'\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Before the while loop\n",
    "ball_images = []  # List to store extracted ball images\n",
    "\n",
    "# In the while loop (after the drawing circles)\n",
    "ball = frame[y-r:y+r, x-r:x+r]\n",
    "if ball.size > 0:\n",
    "    ball_rgb = cv2.cvtColor(ball, cv2.COLOR_BGR2RGB)\n",
    "    ball_images.append(ball_rgb)'\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
